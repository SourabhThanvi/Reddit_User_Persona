{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting_User_Data Using Langchain Document Loader (res:- fail)"
      ],
      "metadata": {
        "id": "HeqQFVosJ0hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrfddm0CgaJQ",
        "outputId": "f04ea726-a53b-4cc0-89e6-2bc7ec686da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.68)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.4)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.7.9)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain_community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Selenium unstructured -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34OU1H3phNEH",
        "outputId": "d737b9e4-6f18-4773-f3fc-b0af9b134f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.6/212.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.7/309.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-YMFzfSfhjn"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import SeleniumURLLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = SeleniumURLLoader(urls=['https://www.reddit.com/r/BollyBlindsNGossip/'], continue_on_failure=True)"
      ],
      "metadata": {
        "id": "eZDsSgxEgY7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgtyO8HNhK4C",
        "outputId": "8a8a96ed-6dcc-463c-d37e-25fb9fb24d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://www.reddit.com/r/BollyBlindsNGossip/', 'title': 'No title found.', 'description': 'No description found.', 'language': 'No language found.'}, page_content=\"\\n\\nYou've been blocked by network security.\\n\\nTo continue, log in to your Reddit account or use your developer token If you think you've been blocked by mistake, file a ticket below and we'll look into it.\\n\\nLog in File a ticket\")]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tried Using reddit api (res :- Pass)"
      ],
      "metadata": {
        "id": "-UEwFaqbKC6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install praw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ohu9NoJiXCDg",
        "outputId": "fbf8f3b2-fa62-4135-a78d-281cf66d1acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.7.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"Put Your ID\",\n",
        "    client_secret='Put Your Secret',\n",
        "    user_agent = 'Agent Name',\n",
        "    check_for_async=False\n",
        ")"
      ],
      "metadata": {
        "id": "JDOFJqEUrzcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reddit.read_only)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVz9qWckXSoX",
        "outputId": "054b0e79-4187-4bf0-fc2d-ce036e358b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "username = \"United_Pineapple_932 \"  # Replace with the Reddit username you want to analyze\n",
        "\n",
        "redditor = reddit.redditor(username)"
      ],
      "metadata": {
        "id": "vo_1f6F4Xf8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts_dict = {}\n",
        "comments_dict = {}\n",
        "\n",
        "# Fetch up to 50 posts\n",
        "for idx, submission in enumerate(redditor.submissions.new(limit=50), 1):\n",
        "    posts_dict[f\"post_{idx}\"] = {\n",
        "        \"title\": submission.title,\n",
        "        \"selftext\": submission.selftext,\n",
        "        \"subreddit\": str(submission.subreddit),\n",
        "        \"created_utc\": submission.created_utc,\n",
        "        \"link\": f\"https://www.reddit.com{submission.permalink}\"\n",
        "    }"
      ],
      "metadata": {
        "id": "YXtOROZOZN1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, comment in enumerate(redditor.comments.new(limit=50), 1):\n",
        "    comments_dict[f\"comment_{idx}\"] = {\n",
        "        \"body\": comment.body,\n",
        "        \"subreddit\": str(comment.subreddit),\n",
        "        \"created_utc\": comment.created_utc,\n",
        "        \"link\": f\"https://www.reddit.com{comment.permalink}\"\n",
        "    }\n"
      ],
      "metadata": {
        "id": "_BsWHVZ7ZPmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts_dict_llm = {\n",
        "    k: {key: val for key, val in v.items() if key != \"link\"}\n",
        "    for k, v in posts_dict.items()\n",
        "}\n",
        "comments_dict_llm = {\n",
        "    k: {key: val for key, val in v.items() if key != \"link\"}\n",
        "    for k, v in comments_dict.items()\n",
        "}"
      ],
      "metadata": {
        "id": "RwoblGpowGra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Gemini Client"
      ],
      "metadata": {
        "id": "JVCdCahlKTNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-ai-generativelanguage==0.6.15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "collapsed": true,
        "id": "dIuopyNKkK2e",
        "outputId": "26a66838-7c5f-4c6c-e2c2-37616947f1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-ai-generativelanguage==0.6.15\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage==0.6.15) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage==0.6.15) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage==0.6.15) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage==0.6.15) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (2025.7.9)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.18\n",
            "    Uninstalling google-ai-generativelanguage-0.6.18:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.18\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.7 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "36afdc3913ee4f27af99f9c8b7406e4b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_data_for_llm = {}\n",
        "\n",
        "for key, value in user_data.items():\n",
        "    value_no_link = {k: v for k, v in value.items() if k != \"link\"}\n",
        "    user_data_for_llm[key] = value_no_link"
      ],
      "metadata": {
        "id": "b1vwv8SkhAVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai"
      ],
      "metadata": {
        "id": "CvY_n-uEhEh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_prompt = (\n",
        "    \"Analyze the following Reddit posts. For each, note any interests, personality traits, or communication styles you observe. \"\n",
        "    \"Summarize the user's characteristics based only on these posts. \"\n",
        "    \"For each trait, cite the title or a snippet from the relevant post.\\n\\n\"\n",
        "    f\"{posts_dict_llm}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "wacunVP4vktM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment_prompt = (\n",
        "    \"Analyze the following Reddit comments. For each, note any interests, personality traits, or communication styles you observe. \"\n",
        "    \"Summarize the user's characteristics based only on these comments. \"\n",
        "    \"For each trait, cite a snippet from the relevant comment.\\n\\n\"\n",
        "    f\"{comments_dict_llm}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "7yU6hQCSwRfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_content = \"\"\n",
        "# for key, value in user_data_for_llm.items():\n",
        "#     if value[\"type\"] == \"comment\":\n",
        "#         user_content += f\"[Comment] (Subreddit: {value['subreddit']}, Time: {value['created_utc']}): {value['body']}\\n\\n\"\n",
        "#     elif value[\"type\"] == \"post\":\n",
        "#         user_content += f\"[Post] (Subreddit: {value['subreddit']}, Time: {value['created_utc']}): Title: {value['title']}\\n{value['selftext']}\\n\\n\"\n",
        "\n",
        "# # Create a short, clear prompt\n",
        "# prompt = (\n",
        "#     f\"Based on the following Reddit posts and comments, generate a brief persona for the user. \"\n",
        "#     f\"Summarize their interests, communication style, and any notable traits.\\n\\n\"\n",
        "#     f\"{user_content}\"\n",
        "# )"
      ],
      "metadata": {
        "id": "QR78_lxZlx5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('gemini2')"
      ],
      "metadata": {
        "id": "87NkLAJPwheo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key = API_KEY)"
      ],
      "metadata": {
        "id": "j7azhFEiwdJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_prompt = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=post_prompt,\n",
        ")"
      ],
      "metadata": {
        "id": "5JREqVZHhODA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_comment = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=comment_prompt,\n",
        ")"
      ],
      "metadata": {
        "id": "AR6LzGhqw01K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthesis_prompt = (\n",
        "    \"Based on the analyses of the user's posts and comments below, synthesize a comprehensive persona. \"\n",
        "    \"Integrate traits from both sources, and ensure each trait is supported by a cited post or comment.\\n\\n\"\n",
        "    f\"Post analysis:\\n{response_prompt.text}\\n\\n\"\n",
        "    f\"Comment analysis:\\n{response_comment.text}\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "0bISs64Ow9Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_persona = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=synthesis_prompt,\n",
        ")"
      ],
      "metadata": {
        "id": "wZtsN8pDxnn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_persona.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "fplJ2tVTxtzu",
        "outputId": "a4edf015-5751-4195-c00a-22f46604e09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the comprehensive analysis of the user\\'s posts and comments, a detailed persona emerges:\\n\\n---\\n\\n## Persona: The Inquisitive Indian Chronicler\\n\\n**Core Identity:**\\n\"The Inquisitive Indian Chronicler\" is a highly engaged, intellectually curious, and meticulously detail-oriented Reddit user with a profound passion for Indian history, culture, and national achievements. They are a dedicated digital archivist and educator, often sharing vast amounts of information and context, while also demonstrating a strong sense of social justice and a sharp, sometimes sarcastic, wit.\\n\\n---\\n\\n### Key Interests:\\n\\n*   **Profound Interest in Indian History & Culture:**\\n    *   **Ancient Civilizations & Archaeology:** Deeply interested in ancient Indian civilizations (Harappan, Indus Valley, Mohenjo-daro), their artifacts, and archaeological theories, including potential links with other ancient cultures. (e.g., Post 4: \"Question: How did such delicate artefacts survive thousands of years...\"; Post 15: \"Around 4500 years old Skeletal remains of a middle aged woman found at Rakhigarhi\"; Post 40: \"possible Mesopotamia links\"; Comment 7: \"I mean 4000+ years of human activities... and still a fragile terracotta toy survived all of this blows my mind man...\").\\n    *   **Art History & Iconography:** Strong appreciation for ancient Indian art, sculpture, and religious iconography, frequently posting detailed images and descriptions of artifacts, often from the National Museum, New Delhi. (e.g., Post 5: \"A 10.5 cm tall prehistoric bronze sculpture\"; Post 12, 18, 29, 39 to `ArtefactPorn`; Post 26: \"Check out the details carved on a fragment of a Torana\").\\n    *   **Religious & Mythological History:** Explores topics like early Buddhism and Hindu mythology, showing an interest in the intellectual concepts and historical context behind religious practices. (e.g., Posts 6, 8, 9: \"Aniconism in early Buddhism\"; Post 18, 19, 22: \"Sage Asita’s visit to Śuddhodana\"; Comment 9: \"By shouldn’t have happened, I meant it was not actually aligned with the original idea of Buddhism creating a contradiction.\").\\n    *   **Modern Indian History & Geopolitics:** Keenly interested in post-colonial Indian history, military conflicts, and current geopolitical dynamics, often with a patriotic lens. (e.g., Post 23, 24: \"Indo-Pakistan War (1947-48)\"; Post 32, 36: \"[Liberation of Goa 1961]\"; Comment 5: \"Is it related to ULFA?\"; Comment 18, 19, 22, 23, 27, 28, 29, 41-43: Extensive debates on India/Pakistan politics and human rights).\\n\\n*   **Indian Space, Aviation, and Defense:** Exhibits significant pride and a concentrated interest in India\\'s advancements and figures in these sectors. (e.g., Posts 1-3, 41-46: Repeated cross-posts about \"Group Captain Shubhanshu Shukla\" and his achievements; Comment 1: \"making it 18 days\" referring to a space mission).\\n\\n*   **Cartography & Geopolitics:** Enjoys historical maps and discussions around geographical and political distributions, including satirical takes. (e.g., Post 13: \"A global map from 1940s\"; Post 28: \"Portuguese presence in Southeast Asia\"; Post 35, 38 to `mapporncirclejerk`).\\n\\n*   **Niche Pop Culture & Wholesome Content:**\\n    *   **Marvel Comics/MCU:** Possesses a deep, analytical knowledge of Marvel character rosters and speculative future storylines. (e.g., Post 27: \"cancelled NEW WARRIORS TV Series\"; Post 31: \"Most probable Champions/Young Avengers lineup.\").\\n    *   **Feline Animals & Humor:** Appreciates cat content and internet humor/memes. (e.g., Post 10, 11: \"The huh? Cat\"; Post 20, 21: \"Embarrassing\" cat posts; Comment 14: \"The cat’s name is Ben/Bender...You can check more info about it on ‘Know your meme’.\").\\n    *   **Positive Social Interactions:** Appreciates wholesome content depicting kindness. (e.g., Post 7: \"Children warmly greet a cheerful, kind elderly watchman\").\\n\\n*   **Language and Continuous Learning:** Shows an explicit interest in the Hindi language, etymology, and enjoys learning new facts. (e.g., Post 37: \"I had no idea Swimming Pool is called ‘तरण ताल’... Good TIL\"; Comment 6: \"Damn ! I had no idea something like this existed !\").\\n\\n---\\n\\n### Personality Traits:\\n\\n*   **Intellectually Curious & Analytical:** Consistently inquisitive, asking direct questions about complex topics and exploring historical or theoretical connections. They enjoy understanding the \"how\" and \"why.\" (e.g., Post 4: \"Question: How did such delicate artefacts survive thousands of years...\"; Post 47: \"A sign of trade with Mesopotamia !?\"; Comment 7: \"I mean 4000+ years of human activities... and still a fragile terracotta toy survived all of this blows my mind man...\"; Comment 10: \"Speculative, analytical, well-informed\").\\n*   **Meticulous & Detail-Oriented:** Exhibits a remarkable attention to detail, providing specific measurements, dates, locations, and minute observations in both posts and comments. (e.g., Post 5: \"10.5 cm tall\"; Post 15: \"Notice the perfect teeth and shell bangles\"; Post 16: \"Photo clicked by me on 15 June 2025\"; Comment 1: \"making it 18 days\"; Comment 26: \"Factual, corrective, precise\").\\n*   **Patriotic & Proud of Indian Heritage:** Demonstrates a deep-seated pride in Indian achievements, history, and cultural identity, often highlighting \"firsts\" or significant national events. (e.g., Posts 41-46: Emphasis on \"first Indian ever\" to ISS; Post 24: Detailed explanation of Indo-Pakistan War from an Indian perspective; Comment 17: Expresses regional pride for an Indian state).\\n*   **Principled & Socially Conscious:** A strong advocate for human rights, fairness, and justice, particularly vocal against systemic discrimination and persecution of minorities. They are not afraid to call out perceived injustices. (e.g., Comment 18, 22, 23: Asserting minority rights and constitutional law; Comment 25: \"How do minorities even breathe in a country where the law itself turns against the victim ?\"; Comment 27: \"Thats really concerning tbh .... Systemic discrimination 100%\").\\n*   **Assertive & Opinionated:** When engaging in debates, especially on socio-political topics, they are direct, challenging, and willing to use strong language or sarcasm to make their point or defend their perspective. (e.g., Comment 19: \"Highly sarcastic, critical, uses rhetorical questions\" regarding Pakistan\\'s governance; Comment 43: \"Highly defensive, confrontational, accusatory, dismissive... Scroll and mind your own business\").\\n*   **Helpful & Advisory:** Proactively offers practical advice, solutions, and informative tips to others, particularly concerning technology, privacy, or efficiency. (e.g., Comment 3: \"Just an advice Next time you share an Instagram link, make sure you remove the part after question mark (?) Your Instagram profile details are exposed...\"; Comment 40: \"More efficient way would be the integration with WhatsApp like we have in Delhi Metro...\").\\n*   **Humble & Open to Correction:** Despite their assertive nature and extensive knowledge, they demonstrate a willingness to admit mistakes and apologize when appropriate, showing maturity and self-awareness. (e.g., Comment 16: \"Oh damn yes… You’re right\"; Comment 50: \"Hello, I am the OOP of the Post...I understand you are upset for not including \\'Jammu\\' in the name and I apologize for the same.\").\\n*   **Engaged Reddit User:** Evidenced by consistent activity, a \"300-day streak,\" frequent cross-posting, and a commitment to contributing original content and participating in discussions. (e.g., Post 25: \"300-day streak unlocked\"; Post 16: \"Photo clicked by me\"; Post 47: \"OC\"; Comment 13: Promises future content).\\n*   **Possesses a Sense of Humor:** Engages with and contributes to humorous and satirical content, including niche internet communities. (e.g., Post 33: \"24 karat Gold Labubu is my whole personality now\" in `CringeTikToks`; Post 35, 38, 50 to `mapporncirclejerk` and `vexilologycirclejerk`; Comment 20: Explains a meme, uses emoji).\\n\\n---\\n\\n### Communication Style:\\n\\n*   **Informative & Educational:** Regularly provides extensive historical, cultural, or biographical context in posts (often in `selftext`) and offers specific facts and citations in comments, positioning themselves as a knowledgeable source. (e.g., Post 18, 22: Extensive selftext explaining \"Sage Asita\"; Post 24: \"extensive historical details with links\" for Indo-Pakistan War; Comment 2: \"Highly detailed, explanatory, educational, provides sources\"; Comment 27: \"In Pakistan, non-Muslims are constitutionally barred from becoming the President... (Article 41(2))\").\\n*   **Strategic Cross-Poster:** Consistently posts the same or very similar content across multiple relevant subreddits to maximize content visibility, discussion, and reach specific audiences. (e.g., Posts 1-3, 6, 8, 9, 10, 11, etc., all demonstrate this pattern).\\n*   **Engaging & Collaborative:** Invites community interaction by posing questions, encouraging closer examination of details, or seeking clarification. (e.g., Post 4: \"Question: How did such delicate artefacts survive...\"; Post 32: \"Try if you can read some of the words here\"; Comment 5: \"Is it related to ULFA?\"; Comment 9: \"Conversational, clarifying\").\\n*   **Direct & Factual:** Titles and descriptions are generally clear, concise, and rich with factual details (dates, locations, names). Comments often convey information directly and factually. (e.g., Posts generally are fact-focused; Comment 1: \"Factual, concise\").\\n*   **Expressive & Emotive:** Uses strong language, rhetorical questions, and occasional emojis to convey passion, surprise, outrage, or approval, making their communication impactful. (e.g., Comment 25: \"How do minorities even breathe... Horrifying AF\"; Comment 6: \"Damn ! I had no idea something like this existed !\"; Comment 9: \"🙂\"; Comment 20: \"😂\").\\n*   **Argumentative & Sarcastic:** Particularly in political discussions, they are adept at crafting counter-arguments, using sarcasm, and direct challenges to express disagreement or criticism. (e.g., Comment 19: \"I hope you guys have a stable government there... definitely NOT elected by the military.\"; Comment 24: \"Heavily sarcastic, critical (`/s`)\").\\n*   **Visual Content Sharer:** Frequently shares images, GIFs, and links in comments to support their points or share information. (e.g., Comment 11, 12, 15, 30, 31, 32, 37, 44, 45).\\n\\n---'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Te4VNfSZaVG3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}